---
title: "Predicting Formation of Calcium Oxalate Crystals in Urine"
author: "Parikshit Patil"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Predicting Formation of Calcium Oxalate Crystals in Urine

```{r}
suppressMessages(library(boot))
which(is.na(urine),arr.ind = TRUE)
```

```{r}
urine <- urine[-c(1,55),]
urine$r <- factor(urine$r, levels= c("0","1"),labels = c("no","yes"))
str(urine)
```

a)  

```{r}
#?urine

library(ggplot2)
```

```{r}
#histogram plots for each predictor(covariate)

ggplot(urine, aes(x=gravity, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))
  #theme(text = element_text(size = 22))
  
ggplot(urine, aes(x=ph, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))

ggplot(urine, aes(x=osmo, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))

ggplot(urine, aes(x=cond, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))

ggplot(urine, aes(x=urea, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))

ggplot(urine, aes(x=calc, fill=r, color=r)) +
  geom_histogram(position="dodge", binwidth=1, aes(y=after_stat(density)))
```

The covariate "calc": seems most likely to be useful in predicting formation of calcium oxalate crystals "r", because through the graphs it can be clearly observed that the ratio of having r vs not increases as calc increases.

b)  

```{r}
#Fit full logistic model
logistic_model = glm(r ~ ., family = binomial, data = urine)
summary(logistic_model)
```

Residual Deviance = 57.56, Degrees of Freedom = 70

This information alone is insufficient to assess if the model fits the data well, as we can show (via L’Hôpital’s rule) that each term in log LSat is zero and the deviance depends only on log LM.

c)  

```{r}
#p-value calculation for hypothesis test

difference = logistic_model$null.deviance - logistic_model$deviance
#difference

#p_value = 1-pchisq(difference,2)
p_value = pchisq(difference,6,lower.tail = FALSE)
p_value
```

The Null Hypothesis is that none of the predictors (null model) are related to the response variable 'r'.

The Alternate Hypothesis is that at least one of the predictors (from full model) are related to the response variable 'r'.

The Test Statistic is the difference of the deviance between the null model (smaller model s) and the full model (larger model l). Test Statistic = 47.6079 $$Test~Statisitic~D_s - D_L = 47.6079$$

The asymptotic distribution is the values of the chi-squared difference between the full model (larger model l) and null model (smaller model s). $$Asymptotic~Distribution = \chi^2_{l-s}$$

Since the p-value is very small (\<0.5), the conclusion is that there exists at least one predictor that is related to the response variable 'r'. We reject the null hypothesis and assume the alternate hypothesis to be true. $$P~Value = 1.415118e-08$$

d)  

```{r}
#AIC Feature Selection

logistic_model_reduced = step(logistic_model, trace=0)
summary(logistic_model_reduced)
```

Using the backward AIC process, the best subset of predictors are: 'gravity', 'cond', 'urea', and 'calc'.

e)  

```{r}
library(pROC)

predicted_probabilities = predict(logistic_model_reduced, type = "response")
roc_obj = roc(response = urine$r, predictor = predicted_probabilities)

#ROC Curve
plot(roc_obj,legacy.axes=FALSE,print.auc=TRUE,print.thres=TRUE,cex.lab=2)

#AUC
AUC = auc(roc_obj)
AUC

roc_logistic = c(coords(roc_obj, "b",
  ret=c("threshold","se","sp"),
  best.method="youden"))

#Threshold, Sensitivity, Specificity values
names(roc_logistic) <- c("Threshold","Sensitivity","Specificity")

t(roc_logistic)
```

Area under the curve = 0.8933

The best probability threshold = 0.4830697

Its corresponding sensitivity = 0.7878788, and specificity = 0.9090909

f)  

```{r}
#Confusion Matrix based on best probability threshold found previously (0.48)

cutoff = 0.48
y_hat = numeric(nrow(urine))
y_hat[which(predicted_probabilities > cutoff)] = 1
conf_mat = table(predicted = y_hat, actual = urine$r)

conf_mat

FPR = 1 - conf_mat[1, 1] / sum(conf_mat[, 1]) # False Positive Rate
TPR = conf_mat[2, 2] / sum(conf_mat[, 2]) # True Positive Rate
PPV = conf_mat[2, 2] / sum(conf_mat[2, ]) # Positive Predictive Value
NPV = conf_mat[1, 1] / sum(conf_mat[1, ]) # Negative Predictive Value

FPR
TPR
PPV
NPV
```

False Positive Rate (FPR) = 0.09090909

True Positive Rate (TPR) = 0.7878788

Positive Predictive Value (PPV) = 0.8666667

Negative Predictive Value (NPV) = 0.8510638

g)  

The model seems effective in predicting the presence of oxilate crystals in the urine, since the TPR, PPV, and NPV are high, especially the AUC. However, we also want to have a higher FPR for healthcare use cases.

h)  

```{r}
# Train-Test Split
set.seed(10)
train_ind <- sample(1:77,51)
train_urine <- urine[train_ind,]
test_urine <- urine[-train_ind,]
```

```{r}
#Fit the full model
logistic_model = glm(r ~ ., family = binomial, data = train_urine)

#Stepwise Feature Selection on full model
logistic_model_best = step(logistic_model, trace=0)
summary(logistic_model_reduced)
```

Using only the training data to determine the best model, the remaining variables are: 'gravity', 'cond', 'urea', and 'calc'. This is the same as in d).

```{r}
predicted_probabilities = predict(logistic_model_best, newdata = test_urine, type = "response")
roc_obj = roc(response = test_urine$r, predictor = predicted_probabilities)

#ROC Curve
plot(roc_obj,legacy.axes=FALSE,print.auc=TRUE,print.thres=TRUE,cex.lab=2)

#AUC
AUC = auc(roc_obj)
AUC

#Threshold, Sensitivity, Specificity
roc_logistic = c(coords(roc_obj, "b",
  ret=c("threshold","se","sp"),
  best.method="youden"))

names(roc_logistic) <- c("Threshold","Sensitivity","Specificity")

t(roc_logistic)
```

Area under the curve = 0.7843

The best probability threshold = 0.5115104

Its corresponding sensitivity = 0.6666667, and specificity = 0.9411765

This result is not as good as the previous model because the AUC of this model is lower.